#并行计算机与并行计算
##并行计算基本条件
1. 硬件(并行机)
2. 并行编程环境
3. 并行算法设计
##并行计算主要目标
1. 提高求解速度
2. 扩大问题规模
3. 减低成本
##并行主要方法
1. 任务分解
2. 功能分解
3. 区域分解
##并行计算机
1. SIMD型并行计算机(Single Instruction Multi-Data)
	1. 同时支持标量指令和向量指令
2. MIMD并行计算机
	1. 多指令流多数据流
	2. 单一的共享地址空间
	3. 存储访问成为性能瓶颈
	4. 典型:SMP
		1. SMP Symmetrical Multi-Processing: 在一个计算机上汇集一组处理器,共享内存等资源,由单一操作系统管理
	5. SIMD适合开发细粒度的数据并行任务,MIMD适合粗粒度的任务并行
3. 分布存储多计算机
	- 松散耦合多机系统
	- 节点独立（可有局部存储、IO设备等）
	- 多地址空间
	- 易于扩展
	- 难于编程
	- 消息传递通信接口
4. 分布共享存储多处理器(Distributed Shared Memory DSM)
	- 将物理上分布的存储系统，通过硬件和软件的办法，向用户提供一个单一的全局地址空间
	- 处理器： 每个结点有一个或多个CPU
	- 分布式存储：每个结点中有存储模块
	- 网络：专用的高性能互联网络连接（Myrinet, Infiniband, …）
	- 单一的操作系统
	- 单一的内存地址空间：所有内存模块都由硬件进行了统一的编址，各个结点既可以直接访问局部内存单元，又可以直接访问其他结点的局部内存单元
	- 可扩展到上百个结点
	- 支持消息传递、共享存储并行程序设计
5. MPP Masively Parallel Processing
	1. 每个节点有自己的操作系统,内存,一个或多个微处理器
6. 集群NOW Network of Workstations或者COW Cluster of Workstations
	- 每个结点都是一个完整的工作站，有独立的硬盘与操作系统
	- 结点间通过低成本的通用网络（如千兆以太网）连接
	- 与MPP 之间的界线越来越模糊
![](http://i.imgur.com/n82Jafm.png)
##并行计算软件环境
1. 操作系统与编程语言
	- 并行计算机主流操作系统：UNIX/Linux/Windows
	- 编程语言
		- Fortran 77/90/95
		- C/C++
		- 其他
	- 三种常见的并行编程环境：
		- 消息传递  MPI PVM
			- MPI提供了更多更高效的通信函数
			- PVM提供了更灵活的功能，如虚拟机的配置，任务的映射等。

		- 共享存储  OpenMP
			- 不是一门新的语言，是对基本语言的扩展。
			- 支持C语言、C++和Fortran；
			- 源代码中加入专用的pragma,编译器可以自动将程序进行并行化，并在必要之处加入同步互斥以及通信。
			- 当选择忽略这些pragma，或者编译器不支持OpenMP时，程序又可退化为通常的程序（一般为串行），代码仍然可以正常运作，只是不能利用多线程来加速程序执行。    
		- 数据并行  HPF
			- 扩展自Fortran 90，它以数据并行的方式工作，使运算工作能够进行分拆，并以扩散方式发派到运算阵列中的各颗处理器上，以此达到高效能运算。
##并行计算效率
![](http://i.imgur.com/pYMSjOO.png)
###Amdahl’s law
- P个处理器，一般而言最大的加速比为p。通常达不到。（考虑到通信开销，任务的分拆，合并等）
- 如果加速比为p，称为线性加速比。
- <b>偶尔会出现超线性加速比</b>
	- 串行算法不合理
	-   特别有利于进行并行计算的独特的结构
	-   算法的不确定性。随机性。
	-   更多的内存。
- 限制加速的因素：
	- 一些处理器处于闲置状态
	- 出现了额外的计算
	- 进程间的通信时间。


